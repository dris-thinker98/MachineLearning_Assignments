# -*- coding: utf-8 -*-
"""MLAssignment5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ba2_w5mCsPZDmye-kcmZwjpFXUUrgr2t
"""

def q2a():
  import matplotlib.pyplot as plt
  from matplotlib import cm
  from sklearn.model_selection import train_test_split
  import numpy as np
  import h5py
  import pickle
  from sklearn.neural_network import MLPClassifier
  from matplotlib.colors import ListedColormap
  from sklearn.preprocessing import StandardScaler
  from sklearn.datasets import make_moons, make_circles, make_classification
  from sklearn.pipeline import make_pipeline
  from sklearn.preprocessing import OneHotEncoder
  from sklearn.manifold import TSNE
  from mlxtend.plotting import plot_decision_regions
  import matplotlib.pyplot as plt
  from sklearn.metrics import log_loss
  from sklearn.decomposition import PCA

  #load train
  f = h5py.File("/content/drive/MyDrive/Colab Notebooks/MLAssignment5/MNIST_Subset.h5", 'r')
  print(list(f.keys()))
  data = f.get('X').value
  labels = f.get('Y').value
  # x_dset, y_dset = f['X'], f['Y']
  unique_labels=np.unique(labels)
  #print(unique_labels)
  print(data.shape, labels.shape)
  #print(data, labels)
  f.close()
  #plt.imshow(data[0])
  data_copy = np.reshape(data, (14251, 784))
  print(data.shape, labels.shape)
  train_data, test_data, train_labels, test_labels = train_test_split(
    data_copy, labels, test_size=0.20, random_state=42)
  
  enc = OneHotEncoder()

  X_train = np.array(train_data)/255 # rescale to values between 0 and 1
  # One-hot encode
  y_train_en = enc.fit_transform(np.array(train_labels).reshape(-1,1)).toarray()

  X_test = np.array(test_data)/255 # rescale
  # One-hot encode
  y_test_en = enc.fit_transform(np.array(test_labels).reshape(-1,1)).toarray()
  
  #part b
  # clf = MLPClassifier(hidden_layer_sizes=(100,50,50), activation = 'logistic', random_state=1, verbose = 'True')
  # clf.fit(X_train, y_train_en)
  # pickle.dump(clf, open("/content/drive/My Drive/Colab Notebooks/MLAssignment5/nn2b.pkl", 'wb'))
  clf_from_pickle = pickle.load(open("/content/drive/My Drive/Colab Notebooks/MLAssignment5/nn2b.pkl", 'rb'))

  loss_nn = (clf_from_pickle.loss_)
  print(clf_from_pickle.n_layers_)
  print(clf_from_pickle.out_activation_)
  #print(clf_from_pickle.coefs_)
  y_predict_test = clf_from_pickle.predict(X_test)
  y_predict_train = clf_from_pickle.predict(X_train)
  test_accuracy = clf_from_pickle.score(X_test, y_test_en)
  train_accuracy = clf_from_pickle.score(X_train, y_train_en)

  y_pred_test_prob = clf_from_pickle.predict_proba(X_test)
  y_pred_train_prob = clf_from_pickle.predict_proba(X_train)
  
  test_lossnn = log_loss(y_test_en, y_pred_test_prob)
  train_losnn = log_loss(y_train_en, y_pred_train_prob)
  print("\nTrain loss : ", loss_nn, "\nTest Loss  : ", test_lossnn)
  print("\nTrain accuracy : ", train_accuracy, "\nTest accuracy  : ", test_accuracy )

  train_data_copy = np.reshape(train_data,(train_data.shape[0], 784))
  test_data_copy = np.reshape(test_data,(test_data.shape[0], 784))

  #not required
  # fig, ax = plt.subplots(figsize=(8,5))
  # plt.plot(clf_from_pickle.loss_curve_)
  
  # plt.figure(figsize=[5,5])
  # train_data_copy = np.reshape(train_data,(train_data.shape[0],28,28))
  # test_data_copy = np.reshape(test_data,(test_data.shape[0],28,28))
  # # Display the first image in training data
  # plt.subplot(121)
  # plt.imshow(train_data_copy[1,:,:], cmap='gray')
  # plt.title("Ground Truth : {}".format(train_labels[1]))

  # # Display the first image in testing data
  # plt.subplot(122)
  # plt.imshow(test_data_copy[3,:,:], cmap='gray')
  # plt.title("Ground Truth : {}".format(test_labels[3]))

  #part c
  tsne=TSNE(n_components=2, random_state=0)
  # tsne_results_tr = tsne.fit_transform(train_data_copy)
  # tsne_results_te = tsne.fit_transform(test_data_copy)
  # np.save("/content/drive/MyDrive/Colab Notebooks/MLAssignment5/tsne_saved_nn.npy",tsne_results_tr)
  tsne_results_tr = np.load("/content/drive/MyDrive/Colab Notebooks/MLAssignment5/tsne_saved_nn.npy")
  # x=np.zeros(50000)
  # y=np.zeros(50000)
  # plt.figure(figsize=(12,8))
  # x=tsne_results[:,0]
  # y=tsne_results[:,1]
  # scatter = plt.scatter(x,y,c=labels,cmap=plt.cm.get_cmap("prism", (10)),marker="o", s=15)
  # classes = ['7','9']
  # plt.legend(handles=scatter.legend_elements()[0], labels=classes,loc="best")
  # # plt.add_artist(legend)
  # # plt.colorbar(ticks=range(10))
  # plt.xlabel("TSNE_1st")
  # plt.ylabel("TSNE_2nd")
  # plt.title("scatter plot for dataset")
  #plt.show()
  
  pca = PCA(n_components = 2)
  
  pca.fit(train_data_copy)
  pca_result_tr = pca.transform(train_data_copy)
  pca_result_te = pca.transform(test_data_copy)
  
  a = [0.0000001, 0.01, 1]
  
  X_tr = tsne_results_tr
  y_tr = train_labels

  
  #try1
  # h = .2
  # xmin, xmax =  X_tr[:, 0].min() - 1 , X_tr[:, 0].max() + 1
  # ymin, ymax =  X_tr[:, 1].min() - 1 , X_tr[:, 1].max() + 1
  # clf2 = MLPClassifier(hidden_layer_sizes=(100,50,50), activation = 'logistic', random_state=1, alpha = 0.01)
  # clf2.fit(X_tr, y_tr)
  # xx, yy = np.meshgrid(np.arange(xmin, xmax, h), np.arange(ymin, ymax, h))
  # Z = clf2.predict(np.c_[xx.ravel(), yy.ravel()])

  # Z= Z.reshape(xx.shape)
  # plt.contourf(xx, yy, Z, cmap = plt.cm.Paired, alpha = 0.8)
  # plt.scatter(X_tr[:, 0], X_tr[:, 1], c = y_tr, cmap = plt.cm.Paired) 

  for values in a:
    # Training a classifier
    clf3 = MLPClassifier(hidden_layer_sizes=(100,50,50), activation = 'logistic', random_state=1, alpha = values)
    clf3.fit(X_tr, y_tr)
    #y_pred = clf.predict(X_tr)
    ypred_tr = clf3.predict(pca_result_tr)
    ypred_te = clf3.predict(pca_result_te)

    # Plotting decision regions
    plt.figure(figsize=(12,8))
    plot_decision_regions(X_tr, y_tr, clf=clf3, legend=2)
    #plot_decision_regions(pca_result_tr, ypred_tr, clf=clf3, legend=2)
    #11400
    # Adding axes annotations
    
    plt.xlabel('tsne first feature')
    plt.ylabel('tsne second feature')
    plt.title('NN on MNIST Subset for alpha : '+str(values))
    plt.show()

     
  
  
q2a()

