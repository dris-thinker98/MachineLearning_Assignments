# -*- coding: utf-8 -*-
"""ML_A4_Q1

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V8fbfNRM4D3MNamv8QFG1kryRahLriV3
"""

!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

"""# **Answer to Q1(a)**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import sys
import os
import joblib    #to save and load models
from sklearn.model_selection import train_test_split 
from random import seed
from random import randrange

data = drive.CreateFile({'id': '1OqVq8A9npcZTcf7XOHRt0Juq_2gUndP8'}) #https://drive.google.com/file/d/1OqVq8A9npcZTcf7XOHRt0Juq_2gUndP8/view?usp=sharing
data.GetContentFile('iris.data')
df = pd.read_csv('iris.data', skiprows=0, header=None, delimiter=',', skip_blank_lines=True)

df.rename(columns = {0:'sepal length in cm',
                     1:'sepal width in cm',
                     2:'petal length in cm',
                     3:'petal width in cm',
                     4:'class'}, inplace = True)

gender = {'Iris-setosa': 0,'Iris-versicolor': 1, 'Iris-virginica': 2} 
#df['class']=pd.factorize(df['class'])[0]+1 
df['class'] = [gender[item] for item in df['class']] 
df

X = df.iloc[:,0:4]
y = df.iloc[:,4]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)            #70:30 split

"""# **Answer to Q1(b)**"""

from sklearn.cluster import KMeans

#elbow method
wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters = i)
    kmeans.fit(X_train)
    wcss.append(kmeans.inertia_)   #here kmeans inertia is also known as within cluster sum of squares

plt.plot(range(1, 11), wcss, marker = 'o')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS') 
plt.title('Elbow Method')
plt.show()

"""# **Answer to Q1(c)**"""

#on original dataset
a=np.array(df['sepal length in cm'])
b=np.array(df['petal length in cm'])
c=np.array(df['class'])

classes=list(df['class'].unique())
classes.sort()
#print(classes)
classes= [str(i) for i in classes]
#print(classes)

plt.figure(figsize=(10,8))
sc_plot=plt.scatter(a,b,c=c)
plt.title("Scatter plot on original dataset")
plt.xlabel("X")
plt.ylabel("Y")
plt.legend(handles=sc_plot.legend_elements()[0],labels=classes)
plt.show()

#scatter plot of the dataset for the optimal number of clusters
kmeans = KMeans(n_clusters = 3,max_iter = 300, n_init = 20)
kmeans.fit(X)
predicted_labels = kmeans.labels_
#predicted_labels

classes=list(pd.Series(predicted_labels).unique())
classes.sort()
#print(classes)
classes= [str(i) for i in classes]
#print(classes)

plt.figure(figsize=(10,8))
sc_plot=plt.scatter(a,b,c=predicted_labels)
plt.title("Scatter plot on predicted labels")
plt.xlabel("X")
plt.ylabel("Y")
plt.legend(handles=sc_plot.legend_elements()[0],labels=classes)
plt.show()

"""# **Answer to Q1(d)**"""

km = KMeans(n_clusters = 3,max_iter = 1000)
km.fit(X_train)
train_pred = km.labels_
acc = accuracy_score(np.array(y_train),train_pred)*100
print(acc)

km.fit(X_test)
test_pred = km.labels_
acc1 = accuracy_score(np.array(y_test),test_pred)*100
print(acc1)